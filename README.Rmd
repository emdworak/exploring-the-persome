---
title: "Persome Analyses and Results"
author: "Elizabeth Dworak"
data: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  github_document:
      toc: true
  html_document:
    toc: true
    toc_float: true
    highlight: "tango"
---

```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

# Overview
This repository includes the code provided in the appendix of [Revelle, Dworak, &amp; Condon (2021)](https://doi.org/10.1016/j.paid.2020.109905)

# A1. Reliability analyses for the SPI data set
```{r}
# Load the packages
library(psych) # make this package active
library(psychTools) # make this one active as well
```

## Find alpha and omega for each scale

```{r}
omA <- omega(spi[selectFromKeys(spi.keys$Agree)],plot=FALSE)
omC <- omega(spi[selectFromKeys(spi.keys$Consc)],plot=FALSE)
omN <- omega(spi[selectFromKeys(spi.keys$Neuro)],plot=FALSE)
omE <- omega(spi[selectFromKeys(spi.keys$Extra)],plot=FALSE)
omO <- omega(spi[selectFromKeys(spi.keys$Open)],plot=FALSE)

omega.h <- c(omA$omega_h,omC$omega_h,omN$omega_h,omE$omega_h,omO$omega_h)
omega.t <- c(omA$omega.tot,omC$omega.tot,omN$omega.tot,omE$omega.tot,omO$omega.tot)
alphas <- c(omA$alpha,omC$alpha ,omN$alpha,omE$alpha,omO$alpha)

omega.df <- data.frame(omgega_total = omega.t,alpha=alphas,omega_h = omega.h)
rownames(omega.df) <- cs(Agreeableness, Conscientiousness, Neuroticism,
                         Extraversion, Openness)
```

## Find the scale scores for the Big 5 and little 27

```{r}
spi.scales <- scoreItems(spi.keys,spi) #find scores as well as scale statistics
spi.scores <- data.frame(spi[1:10],spi.scales$scores) #combine demographics and scores
R5<- lowerCor(spi.scores[11:15])
basic.stats <- cbind(omega.df,R5)
```

```{r}
basic.stats
```

# A2. Regression analyses for the SPI data set 
```{r, eval=FALSE}
library(psych) #make this package active
library(psychTools) #make this one active as well
```

```{r}
spi.scales <- scoreItems(spi.keys,spi) #find scores as well as scale statistics
spi.scores <- data.frame(spi[1:10],spi.scales$scores) #combine demographics and scores
set.seed(42) #set the random seed to a memorable value
ss <- sample(1:4000,2000,replace=FALSE) #randomly choose 2000 subjects
spi5.R <- setCor(y=1:10,x=11:15,data=spi.scores[ss,],plot=FALSE)
spi27.R <- setCor(y=1:10,x=16:42,data=spi.scores[ss,],plot=FALSE)
spi135.R <- setCor(y=1:10,x=11:145,data=spi[ss,],plot=FALSE)

spi.scales <- scoreItems(spi.keys,spi) #find scores as well as scale statistics
sc.demos <- data.frame(spi[1:10],spi.scales$scores) #combine demographics and scores
#sc.demos <-cbind(spi[1:10],sc$scores) #combine with scores with demographics
set.seed(42) #for reproducible results
ss <- sample(1:nrow(sc.demos),nrow(sc.demos)/2)
#derivation multiple Rs
sc.5 <- setCor(y=1:10,x=11:15, data=sc.demos[ss,], plot=FALSE)
sc.27 <- setCor(y=1:10,x=16:42, data=sc.demos[ss,], plot=FALSE)
sc.135 <- setCor(y=1:10,x=11:145,data=spi[ss,] ,plot=FALSE)
#now cross validate
cv.5 <- crossValidation(sc.5,sc.demos[-ss,])


cv.27 <- crossValidation(sc.27,sc.demos[-ss,])
cv.135 <- crossValidation(sc.135,spi[-ss,])
cross.valid.df <- data.frame(cv5=cv.5$crossV, cv.27=cv.27$crossV, cv135=cv.135$crossV)
cross.valid.df.sorted <- dfOrder(cross.valid.df,1)
bs <- bestScales(spi[ss,],criteria=colnames(spi)[1:10], folds=10, n.item=20,
                 dictionary=spi.dictionary,cut=.05)
bs.cv <- crossValidation(bs,spi[-ss,])
cross.valid.df.bs <- cbind(cross.valid.df,bs=bs.cv$crossV)
cv.df.bs.sorted <- dfOrder(cross.valid.df.bs,1)
matPlot(cv.df.bs.sorted[c(2,4,6,8)],minlength=8,
        main="Cross validation of multiple regression on spi data",
        xlas=3, ylab="Cross Validated R", pch=15:19)
legend(1,.6,cs(135,27,bestS,b5),lty=c(3,2,4,1),col=c(3,2,4,1))

bs.spi.smoke <- bs$items$smoke
```

```{r, eval = FALSE}
df2latex(bs.spi.smoke[c(2,3,5)])
```


```{r}
bs.spi.smoke[c(2,3,5)]
```



# A3. Graphical displays: The Manhattan plot

# A4. Studies 3 and 4: Predicting 19 criteria from 696 items and scales 

# A5. Study 5: Applying large sample profiles to a smaller sample